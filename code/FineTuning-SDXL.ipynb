{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09c673d",
   "metadata": {},
   "source": [
    "# Fine-Tuning StableDiffusion XL with DreamBooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aac13c",
   "metadata": {},
   "source": [
    "Over the past few years Generative AI models have popped up everywhere - from creating realistic responses to complex questions, to generating images and music to impress art critics around the globe. In this notebook we use the Hugging Face [Stable Diffusion XL (SDXL)](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) model to create images from text prompts. You'll see how to import the SDXL model and use it to generate an image. \n",
    "\n",
    "From there, you'll see how you can fine-tune the model using [DreamBooth](https://huggingface.co/docs/diffusers/training/dreambooth), a method for easily fine-tuning a text-to-image model. We'll use a small number of photos of [Toy Jensen](https://blogs.nvidia.com/blog/2022/12/22/toy-jensen-jingle-bells/) in this notebook to fine-tune SDXL. This will allow us to generate new images that include Toy Jensen! \n",
    "\n",
    "After that, you'll have the chance to fine-tune the model on your own images. Perhaps you want to create an image of you at the bottom of the ocean, or in outer space? By the end of this notebook you will be able to! \n",
    "\n",
    "**IMPORTANT:** This project will utilize additional third-party open source software. Review the license terms of these open source projects before use. Third party components used as part of this project are subject to their separate legal notices or terms that accompany the components. You are responsible for confirming compliance with third-party component license terms and requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee02dd",
   "metadata": {},
   "source": [
    "### Stable Diffusion XL Model\n",
    "\n",
    "First, we import the classes and libraries we need to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff19a5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DDUFEntry' from 'huggingface_hub' (/home/workbench/.local/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionXLPipeline, DiffusionPipeline\n",
      "File \u001b[0;32m/workspace/diffusers/src/diffusers/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.33.0.dev0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     DIFFUSERS_SLOW_IMPORT,\n\u001b[1;32m      7\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m      8\u001b[0m     _LazyModule,\n\u001b[1;32m      9\u001b[0m     is_flax_available,\n\u001b[1;32m     10\u001b[0m     is_k_diffusion_available,\n\u001b[1;32m     11\u001b[0m     is_librosa_available,\n\u001b[1;32m     12\u001b[0m     is_note_seq_available,\n\u001b[1;32m     13\u001b[0m     is_onnx_available,\n\u001b[1;32m     14\u001b[0m     is_scipy_available,\n\u001b[1;32m     15\u001b[0m     is_sentencepiece_available,\n\u001b[1;32m     16\u001b[0m     is_torch_available,\n\u001b[1;32m     17\u001b[0m     is_torchsde_available,\n\u001b[1;32m     18\u001b[0m     is_transformers_available,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Lazy Import based on\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# https://github.com/huggingface/transformers/blob/main/src/transformers/__init__.py\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# When adding a new object to this init, please add it to `_import_structure`. The `_import_structure` is a dictionary submodule to list of object names,\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# and is used to defer the actual importing for when the objects are requested.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# This way `import diffusers` provides the names in the namespace without actually importing anything (and especially none of the backends).\u001b[39;00m\n\u001b[1;32m     29\u001b[0m _import_structure \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFromOriginalModelMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     ],\n\u001b[1;32m     54\u001b[0m }\n",
      "File \u001b[0;32m/workspace/diffusers/src/diffusers/utils/__init__.py:43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_modules_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_to_gif, export_to_obj, export_to_ply, export_to_video\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     44\u001b[0m     PushToHubMixin,\n\u001b[1;32m     45\u001b[0m     _add_variant,\n\u001b[1;32m     46\u001b[0m     _get_checkpoint_shard_files,\n\u001b[1;32m     47\u001b[0m     _get_model_file,\n\u001b[1;32m     48\u001b[0m     extract_commit_hash,\n\u001b[1;32m     49\u001b[0m     http_user_agent,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     52\u001b[0m     BACKENDS_MAPPING,\n\u001b[1;32m     53\u001b[0m     DIFFUSERS_SLOW_IMPORT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     requires_backends,\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_module_from_name, get_submodule_by_name, load_image, load_video\n",
      "File \u001b[0;32m/workspace/diffusers/src/diffusers/utils/hub_utils.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Union\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m uuid4\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     DDUFEntry,\n\u001b[1;32m     29\u001b[0m     ModelCard,\n\u001b[1;32m     30\u001b[0m     ModelCardData,\n\u001b[1;32m     31\u001b[0m     create_repo,\n\u001b[1;32m     32\u001b[0m     hf_hub_download,\n\u001b[1;32m     33\u001b[0m     model_info,\n\u001b[1;32m     34\u001b[0m     snapshot_download,\n\u001b[1;32m     35\u001b[0m     upload_folder,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY, HF_HUB_OFFLINE\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m REGEX_COMMIT_HASH\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DDUFEntry' from 'huggingface_hub' (/home/workbench/.local/lib/python3.10/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, DiffusionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33488fe1",
   "metadata": {},
   "source": [
    "Next, from the Hugging Face `diffusers` library, we create a `StableDiffusionXLPipeline` object from the SDXL base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2c6c66-08e4-4931-adf7-f3886ec7eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version              Editable project location\n",
      "------------------------- -------------------- -------------------------\n",
      "absl-py                   1.4.0\n",
      "accelerate                1.0.1\n",
      "aiofiles                  23.2.1\n",
      "aiohttp                   3.8.5\n",
      "aiosignal                 1.3.1\n",
      "altair                    5.5.0\n",
      "annotated-types           0.5.0\n",
      "anyio                     4.8.0\n",
      "apex                      0.1\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.0\n",
      "astunparse                1.6.3\n",
      "async-lru                 2.0.4\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.1.0\n",
      "audioread                 3.0.0\n",
      "babel                     2.16.0\n",
      "backcall                  0.2.0\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.0.0\n",
      "blis                      0.7.10\n",
      "cachetools                5.3.1\n",
      "catalogue                 2.0.9\n",
      "certifi                   2023.7.22\n",
      "cffi                      1.15.1\n",
      "charset-normalizer        3.2.0\n",
      "click                     8.1.8\n",
      "cloudpickle               2.2.1\n",
      "cmake                     3.27.4.1\n",
      "comm                      0.1.4\n",
      "confection                0.1.3\n",
      "contourpy                 1.1.0\n",
      "cubinlinker               0.3.0+2.gce0680b\n",
      "cuda-python               12.2.0rc5+5.g84845d1\n",
      "cudf                      23.8.0\n",
      "cugraph                   23.8.0\n",
      "cugraph-dgl               23.8.0\n",
      "cugraph-service-client    23.8.0\n",
      "cugraph-service-server    23.8.0\n",
      "cuml                      23.8.0\n",
      "cupy-cuda12x              12.1.0\n",
      "cycler                    0.11.0\n",
      "cymem                     2.0.7\n",
      "Cython                    3.0.2\n",
      "dask                      2023.7.1\n",
      "dask-cuda                 23.8.0\n",
      "dask-cudf                 23.8.0\n",
      "dataclass-wizard          0.23.0\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "diffusers                 0.33.0.dev0          /workspace/diffusers\n",
      "distributed               2023.7.1\n",
      "dm-tree                   0.1.8\n",
      "dnspython                 2.7.0\n",
      "einops                    0.6.1\n",
      "email_validator           2.2.0\n",
      "exceptiongroup            1.1.3\n",
      "execnet                   2.0.2\n",
      "executing                 1.2.0\n",
      "expecttest                0.1.3\n",
      "fastapi                   0.111.0\n",
      "fastapi-cli               0.0.7\n",
      "fastjsonschema            2.18.0\n",
      "fastrlock                 0.8.1\n",
      "ffmpy                     0.5.0\n",
      "filelock                  3.12.4\n",
      "flash-attn                2.0.4\n",
      "fonttools                 4.42.1\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.0\n",
      "fsspec                    2023.6.0\n",
      "gast                      0.5.4\n",
      "google-auth               2.23.0\n",
      "google-auth-oauthlib      0.4.6\n",
      "gradio                    4.35.0\n",
      "gradio_client             1.0.1\n",
      "graphsurgeon              0.4.6\n",
      "grpcio                    1.58.0\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httptools                 0.6.4\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.21.4\n",
      "hypothesis                5.35.1\n",
      "idna                      3.4\n",
      "importlib-metadata        6.8.0\n",
      "importlib_resources       6.5.2\n",
      "iniconfig                 2.0.0\n",
      "inquirerpy                0.3.4\n",
      "intel-openmp              2021.4.0\n",
      "ipykernel                 6.25.2\n",
      "ipython                   8.15.0\n",
      "ipython-genutils          0.2.0\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.0\n",
      "Jinja2                    3.1.2\n",
      "joblib                    1.3.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.19.0\n",
      "jsonschema-specifications 2023.7.1\n",
      "jupyter_client            8.3.1\n",
      "jupyter_core              5.3.1\n",
      "jupyter-events            0.11.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyter-tensorboard       0.2.0\n",
      "jupyterlab                4.3.4\n",
      "jupyterlab-pygments       0.2.2\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "jupytext                  1.15.1\n",
      "kiwisolver                1.4.5\n",
      "langcodes                 3.3.0\n",
      "librosa                   0.9.2\n",
      "llvmlite                  0.40.1\n",
      "locket                    1.0.0\n",
      "Markdown                  3.4.4\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib                3.7.3\n",
      "matplotlib-inline         0.1.6\n",
      "mdit-py-plugins           0.4.0\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.1\n",
      "mkl                       2021.1.1\n",
      "mkl-devel                 2021.1.1\n",
      "mkl-include               2021.1.1\n",
      "mock                      5.1.0\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.0.5\n",
      "multidict                 6.0.4\n",
      "murmurhash                1.0.9\n",
      "narwhals                  1.23.0\n",
      "nbclient                  0.8.0\n",
      "nbconvert                 7.8.0\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.7\n",
      "networkx                  2.6.3\n",
      "ninja                     1.11.1\n",
      "notebook                  6.4.10\n",
      "notebook_shim             0.2.4\n",
      "numba                     0.57.1+1.g5fba9aa8f\n",
      "numpy                     1.26.4\n",
      "nvidia-cublas-cu12        12.1.3.1\n",
      "nvidia-cuda-cupti-cu12    12.1.105\n",
      "nvidia-cuda-nvrtc-cu12    12.1.105\n",
      "nvidia-cuda-runtime-cu12  12.1.105\n",
      "nvidia-cudnn-cu12         8.9.2.26\n",
      "nvidia-cufft-cu12         11.0.2.54\n",
      "nvidia-curand-cu12        10.3.2.106\n",
      "nvidia-cusolver-cu12      11.4.5.107\n",
      "nvidia-cusparse-cu12      12.1.0.106\n",
      "nvidia-dali-cuda120       1.29.0\n",
      "nvidia-nccl-cu12          2.18.1\n",
      "nvidia-nvjitlink-cu12     12.6.85\n",
      "nvidia-nvtx-cu12          12.1.105\n",
      "nvidia-pyindex            1.0.9\n",
      "nvtx                      0.2.5\n",
      "oauthlib                  3.2.2\n",
      "onnx                      1.14.0\n",
      "opencv                    4.7.0\n",
      "orjson                    3.10.15\n",
      "overrides                 7.7.0\n",
      "packaging                 23.1\n",
      "pandas                    1.5.3\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.3\n",
      "partd                     1.4.0\n",
      "pathy                     0.10.2\n",
      "peft                      0.9.0\n",
      "pexpect                   4.8.0\n",
      "pfzy                      0.3.4\n",
      "pickleshare               0.7.5\n",
      "Pillow                    9.2.0\n",
      "pip                       23.2.1\n",
      "platformdirs              3.10.0\n",
      "pluggy                    1.3.0\n",
      "ply                       3.11\n",
      "polygraphy                0.49.0\n",
      "pooch                     1.7.0\n",
      "preshed                   3.0.8\n",
      "prettytable               3.9.0\n",
      "prometheus-client         0.17.1\n",
      "prompt-toolkit            3.0.39\n",
      "protobuf                  4.24.3\n",
      "psutil                    5.9.4\n",
      "ptxcompiler               0.8.1+1.g2cb1b35\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   11.0.0\n",
      "pyasn1                    0.5.0\n",
      "pyasn1-modules            0.3.0\n",
      "pybind11                  2.11.1\n",
      "pycocotools               2.0+nv0.7.3\n",
      "pycparser                 2.21\n",
      "pydantic                  2.3.0\n",
      "pydantic_core             2.6.3\n",
      "pydub                     0.25.1\n",
      "Pygments                  2.16.1\n",
      "pylibcugraph              23.8.0\n",
      "pylibcugraphops           23.8.0\n",
      "pylibraft                 23.8.0\n",
      "pynvml                    11.4.1\n",
      "pyparsing                 3.1.1\n",
      "pytest                    7.4.2\n",
      "pytest-flakefinder        1.1.0\n",
      "pytest-rerunfailures      12.0\n",
      "pytest-shard              0.1.2\n",
      "pytest-xdist              3.3.1\n",
      "python-dateutil           2.8.2\n",
      "python-dotenv             1.0.1\n",
      "python-hostlist           1.23.0\n",
      "python-json-logger        3.2.1\n",
      "python-multipart          0.0.20\n",
      "pytorch-quantization      2.1.2\n",
      "pytz                      2023.3\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.1\n",
      "raft-dask                 23.8.0\n",
      "referencing               0.30.2\n",
      "regex                     2023.8.8\n",
      "requests                  2.31.0\n",
      "requests-oauthlib         1.3.1\n",
      "resampy                   0.4.2\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.9.4\n",
      "rich-toolkit              0.13.2\n",
      "rmm                       23.8.0\n",
      "rpds-py                   0.10.3\n",
      "rsa                       4.9\n",
      "ruff                      0.9.2\n",
      "safetensors               0.5.2\n",
      "scikit-learn              1.2.0\n",
      "scipy                     1.14.1\n",
      "semantic-version          2.10.0\n",
      "Send2Trash                1.8.2\n",
      "setuptools                68.2.2\n",
      "shellingham               1.5.4\n",
      "six                       1.16.0\n",
      "smart-open                6.4.0\n",
      "sniffio                   1.3.1\n",
      "sortedcontainers          2.4.0\n",
      "soundfile                 0.12.1\n",
      "soupsieve                 2.5\n",
      "spacy                     3.6.1\n",
      "spacy-legacy              3.0.12\n",
      "spacy-loggers             1.0.5\n",
      "sphinx-glpi-theme         0.3\n",
      "srsly                     2.4.7\n",
      "stack-data                0.6.2\n",
      "starlette                 0.37.2\n",
      "sympy                     1.12\n",
      "tabulate                  0.9.0\n",
      "tbb                       2021.10.0\n",
      "tblib                     2.0.0\n",
      "tensorboard               2.9.0\n",
      "tensorboard-data-server   0.6.1\n",
      "tensorboard-plugin-wit    1.8.1\n",
      "tensorrt                  8.6.1\n",
      "terminado                 0.17.1\n",
      "thinc                     8.1.12\n",
      "threadpoolctl             3.2.0\n",
      "thriftpy2                 0.4.16\n",
      "tinycss2                  1.2.1\n",
      "tokenizers                0.19.1\n",
      "toml                      0.10.2\n",
      "tomli                     2.0.1\n",
      "tomlkit                   0.12.0\n",
      "toolz                     0.12.0\n",
      "torch                     2.1.0\n",
      "torch-tensorrt            2.0.0.dev0\n",
      "torchdata                 0.7.0a0\n",
      "torchtext                 0.16.0a0\n",
      "torchvision               0.16.0\n",
      "tornado                   6.3.3\n",
      "tqdm                      4.66.1\n",
      "traitlets                 5.9.0\n",
      "transformer-engine        0.12.0+170797\n",
      "transformers              4.40.2\n",
      "treelite                  3.2.0\n",
      "treelite-runtime          3.2.0\n",
      "triton                    2.1.0+e621604\n",
      "typer                     0.15.1\n",
      "types-dataclasses         0.6.6\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "ucx-py                    0.33.0\n",
      "uff                       0.6.9\n",
      "ujson                     5.10.0\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "uvicorn                   0.32.0\n",
      "uvloop                    0.21.0\n",
      "wasabi                    1.1.2\n",
      "watchfiles                1.0.4\n",
      "wcwidth                   0.2.6\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "websockets                11.0.3\n",
      "Werkzeug                  2.3.7\n",
      "wheel                     0.41.2\n",
      "widgetsnbextension        4.0.13\n",
      "xdoctest                  1.0.2\n",
      "xgboost                   1.7.5\n",
      "yarl                      1.9.2\n",
      "zict                      3.0.0\n",
      "zipp                      3.16.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341950bf-6878-4a31-8af6-f641a1a8c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting chardet\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bae0e-edd9-4d54-b72f-9e8a75493896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6042e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e1a6e",
   "metadata": {},
   "source": [
    "Let's use the SDXL model to generate an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"toy jensen in space\"\n",
    "image = pipe(prompt=prompt).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0dad2",
   "metadata": {},
   "source": [
    "Hmmm, looks like the Hugging Face SDXL model doesn't know about Toy Jensen! Imagine that! \n",
    "\n",
    "✅ Try using the SDXL model to generate some other images by editing the text in the first line of the cell above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5795a7",
   "metadata": {},
   "source": [
    "## Fine-Tuning the model with DreamBooth\n",
    "\n",
    "Fine-Tuning is used to train an existing Machine Learning Model, given new information. In our case, we want to teach the SDXL model about Toy Jensen. This will allow us to create the perfect image of Toy Jensen in Space!\n",
    "\n",
    "[DreamBooth](https://arxiv.org/abs/2208.12242) provides a way to fine-tune a text-to-image model using only a few images. Let's use this to tune our SDXL Model so that it knows about Toy Jensen!\n",
    "\n",
    "We have 8 photos of Toy Jensen in our dataset - let's take a look at one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "display(Image(filename='../data/toy-jensen/tj1.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1611c557",
   "metadata": {},
   "source": [
    "Now we can use Hugging Face and DreamBooth to fine-tune this model. To do this we create a config, then specify some flags like an instance prompt, a resolution and a number of training steps for the fine-tuning algorithm to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch /workspace/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=stabilityai/stable-diffusion-xl-base-1.0  \\\n",
    "  --instance_data_dir=/project/data/toy-jensen \\\n",
    "  --output_dir=/project/models/tuned-toy-jensen \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --instance_prompt=\"a photo of toy jensen\" \\\n",
    "  --resolution=1024 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=100 \\\n",
    "  --seed=\"0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa7268",
   "metadata": {},
   "source": [
    "Now that the model is fine-tuned, let's tell our notebook where to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f899ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(\"/project/models/tuned-toy-jensen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b5ee85",
   "metadata": {},
   "source": [
    "Finally, we can use our fine-tuned model to create an image with Toy Jensen in it. Let's give it a go! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\"A picture of toy jensen in space\", num_inference_steps=75).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb09409",
   "metadata": {},
   "source": [
    "Wow - look at him go! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39851c0",
   "metadata": {},
   "source": [
    "### Trying out some more examples\n",
    "\n",
    "\n",
    "The SDXL model we are using was trained on historical data, and knows about everything from celebrities to famous buildings. However, it was trained on data up to a fixed point in time and isn't up to date with things and people who have become famous in the last few months.\n",
    "\n",
    "For example, King Charles III became king of the United Kingdom in September 2022. Let's ask our SDXL Model for an image of King Charles in Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"King Charles in space\"\n",
    "image = pipe(prompt=prompt).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0a65a",
   "metadata": {},
   "source": [
    "Did it give you an image of a King Charles spaniel? Or maybe King Charles II? That's not what we were hoping for! \n",
    "\n",
    "1. Let's gather some (10ish) images of King Charles III from your favourite search engine. Copy those images into the `data/charles-3/` folder. You can download then to your machine and move them to this folder. \n",
    "\n",
    "    **Reminder:** Third party components used as part of this project are subject to their separate legal notices or terms that accompany the components; you are responsible for reviewing and confirming compliance with third-party component license terms and requirements.\n",
    "2. Run the code below to fine-tune the model on your images of King Charles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf45d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the .gitkeep file in the 'charles-3' folder.\n",
    "!rm ../data/charles-3/.gitkeep\n",
    "!rm -rf ../data/charles-3/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch /workspace/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=stabilityai/stable-diffusion-xl-base-1.0  \\\n",
    "  --instance_data_dir=/project/data/charles-3 \\\n",
    "  --output_dir=/project/models/tuned-charles-3 \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --instance_prompt=\"a photo of King Charles\" \\\n",
    "  --resolution=1024 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --learning_rate=2e-4 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=150 \\\n",
    "  --seed=\"0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e68be4",
   "metadata": {},
   "source": [
    "Now we load the model and use it to generate an image of King Charles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(\"/project/models/tuned-charles-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd059b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\"A picture of King Charles in space\", num_inference_steps=75).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333d426",
   "metadata": {},
   "source": [
    "How is the model performing? Do you need to train it on a few more images? If so, add some more images to the folder then run the cells above to retrain. \n",
    "\n",
    "Now, the model knows what King Charles III looks like and is able to generate realistic images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0436ad5",
   "metadata": {},
   "source": [
    "\n",
    "## Fine-tuning the Model on your own data\n",
    "\n",
    "✅ Why not try out training the SDXL model on your own set of images? Follow the steps below to get set up to train your own model. \n",
    "\n",
    "**Reminder:** Third party components used as part of this project are subject to their separate legal notices or terms that accompany the components; you are responsible for reviewing and confirming compliance with third-party component license terms and requirements.\n",
    "\n",
    "\n",
    "1. You'll need to find around 10 different pictures of your chosen item. Why not find some of your pet or your car? \n",
    "\n",
    "2. Save those images into the `data/my-data` folder we have created for you, similarly to as you have done with the input images of King Charles III.\n",
    "\n",
    "3. Edit the 'instance_prompt' line the code below so that it reflects your item. For example, you could change it to \n",
    "```--instance_prompt=\"a photo of my cat alice\"```\n",
    "\n",
    "4. Once you've updated the prompt, run the cells below to train the model on your data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the .gitkeep file in the 'my-data' folder.\n",
    "!rm ../data/my-data/.gitkeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4daa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch /workspace/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=stabilityai/stable-diffusion-xl-base-1.0  \\\n",
    "  --instance_data_dir=/project/data/my-data \\\n",
    "  --output_dir=/project/models/tuned-my-data \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --instance_prompt=\"a photo of [CHANGE THIS]\" \\\n",
    "  --resolution=1024 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c2e7f",
   "metadata": {},
   "source": [
    "Now that your model has been trained we can load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f2f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(\"/project/models/tuned-my-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1ac18",
   "metadata": {},
   "source": [
    "And finally, use the code below to generate images. Change the prompt to something which includes your item. For example:\n",
    "\n",
    "`image = pipe(\"A picture of my cat alice in space)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb50913",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\"A picture of [CHANGE THIS] in space\", num_inference_steps=75).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672d403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
